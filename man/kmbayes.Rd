% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bkmr_main_functions.R
\name{kmbayes}
\alias{kmbayes}
\title{Fit Bayesian kernel machine regression}
\usage{
kmbayes(y, Z, X = NULL, iter = 1000, family = "gaussian", id = NULL,
  verbose = TRUE, Znew = NULL, starting.values = NULL,
  control.params = NULL, varsel = FALSE, groups = NULL, knots = NULL,
  ztest = NULL, rmethod = "varying", est.h = FALSE)
}
\arguments{
\item{y}{a vector of outcome data of length \code{n}.}

\item{Z}{an \code{n}-by-\code{M} matrix of predictor variables to be included in the \code{h} function. Each row represents an observation and each column represents an predictor.}

\item{X}{an \code{n}-by-\code{K} matrix of covariate data where each row represents an observation and each column represents a covariate. Should not contain an intercept column.}

\item{iter}{number of iterations to run the sampler}

\item{family}{a description of the error distribution and link function to be used in the model. Currently implemented for \code{gaussian} and \code{binomial} families.}

\item{id}{optional vector (of length \code{n}) of grouping factors for fitting a model with a random intercept. If NULL then no random intercept will be included.}

\item{verbose}{TRUE or FALSE: flag indicating whether to print intermediate diagnostic information during the model fitting.}

\item{Znew}{optional matrix of new predictor values at which to predict \code{h}, where each row represents a new observation. This will slow down the model fitting, and can be done as a post-processing step using \code{\link{SamplePred}}}

\item{starting.values}{list of starting values for each parameter. If not specified default values will be chosen.}

\item{control.params}{list of parameters specifying the prior distributions and tuning parameters for the MCMC algorithm. If not specified default values will be chosen.}

\item{varsel}{TRUE or FALSE: indicator for whether to conduct variable selection on the Z variables in \code{h}}

\item{groups}{optional vector (of length \code{M}) of group indictors for fitting hierarchical variable selection if varsel=TRUE. If varsel=TRUE without group specification, component-wise variable selections will be performed.}

\item{knots}{optional matrix of knot locations for implementing the Gaussian predictive process of Banerjee et al (2008). Currently only implemented for models without a random intercept.}

\item{ztest}{optional vector indicating on which variables in Z to conduct variable selection (the remaining variables will be forced into the model).}

\item{rmethod}{for those predictors being forced into the \code{h} function, the method for sampling the \code{r[m]} values. Takes the value of 'varying' to allow separate \code{r[m]} for each predictor; 'equal' to force the same \code{r[m]} for each predictor; or 'fixed' to fix the \code{r[m]} to their starting values}

\item{est.h}{TRUE or FALSE: indicator for whether to sample from the posterior distribution of the subject-specific effects h_i within the main sampler. This will slow down the model fitting.}
}
\value{
an object of class "bkmrfit", which has the associated methods:
\itemize{
  \item \code{\link{print}} (i.e., \code{\link{print.bkmrfit}}) 
  \item \code{\link{summary}} (i.e., \code{\link{summary.bkmrfit}})
}
}
\description{
Fits the Bayesian kernel machine regression (BKMR) model using Markov chain Monte Carlo (MCMC) methods.
}
\references{
Bobb, JF, Valeri L, Claus Henn B, Christiani DC, Wright RO, Mazumdar M, Godleski JJ, Coull BA (2015). Bayesian Kernel Machine Regression for Estimating the Health Effects of Multi-Pollutant Mixtures. Biostatistics 16, no. 3: 493-508.

Banerjee S, Gelfand AE, Finley AO, Sang H (2008). Gaussian predictive process models for large spatial data sets. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70(4), 825-848.
}
\seealso{
For guided examples, go to \url{https://jenfb.github.io/bkmr/overview.html}
}
